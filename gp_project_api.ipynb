{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb0fa36",
   "metadata": {},
   "source": [
    "### installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d42f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#python 3.8 change it in anonconda environment create new one and install jupyter for it and open\n",
    "!pip3 install Flask\n",
    "!pip3 install Werkzeug\n",
    "!pip install flask_cors\n",
    "!pip install json\n",
    "!pip install torchaudio\n",
    "!pip install torch\n",
    "!pip install denoiser\n",
    "!pip install deepspeech\n",
    "!pip install ffmpeg #add path in variable environment windows\n",
    "!pip install pydub\n",
    "\n",
    "# before pip install flask_classful and restart jupyter\n",
    "# Flask-SocketIO==4.3.1\n",
    "# python-engineio==3.13.2\n",
    "# python-socketio==4.6.0\n",
    "# Flask==2.0.3\n",
    "# Werkzeug==2.0.3\n",
    "\n",
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4942cfb2",
   "metadata": {},
   "source": [
    "### Import  libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec59c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json                            #deal with json files\n",
    "from IPython import display as disp    # Required for denoiser Pretraind model [denoiser]\n",
    "import torch                           # Required for denoiser Pretraind model [denoiser]\n",
    "import torchaudio                      # Required for denoiser Pretraind model [denoiser]\n",
    "from denoiser import pretrained        # Required for denoiser Pretraind model [denoiser]\n",
    "from denoiser.dsp import convert_audio # Required for denoiser Pretraind model [denoiser]\n",
    "from flask import Flask,request        # api\n",
    "from flask_classful import FlaskView, route #api class\n",
    "from flask_cors import CORS, cross_origin\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import wave\n",
    "from keras import models\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba92346",
   "metadata": {},
   "source": [
    "### Init app for creating api functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cdc5823",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "cors = CORS(app)\n",
    "app.config['CORS_HEADERS'] = 'Content-Type'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4503ed7d",
   "metadata": {},
   "source": [
    "### deep speech api functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdfb39bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSpeech(FlaskView):\n",
    "    def __init__(self):\n",
    "        self.deep_speech_pb=\"\"\n",
    "        self.deep_speech_scorer=\"\"\n",
    "        self.recorded_wav=\"\"\n",
    "        self.denoised_wav=\"\"\n",
    "        self.json_path=\"\"\n",
    "    @route(\"/path\")\n",
    "    def set_paths(self):\n",
    "        paths = json.loads(request.data)\n",
    "        self.deep_speech_pb=paths[\"pb_model\"]\n",
    "        self.deep_speech_scorer=paths[\"scorer_model\"]\n",
    "        self.recorded_wav=paths[\"record\"]\n",
    "        self.denoised_wav=paths[\"denoised_record\"]\n",
    "        self.json_path=paths[\"output_json\"]\n",
    "        self.meta_data=paths[\"meta_data\"]\n",
    "        self.generated_wav=paths[\"hkm_record\"]\n",
    "        self.root=paths[\"root\"]\n",
    "    def get_root_path(self):\n",
    "        return self.root\n",
    "    def get_record_path(self):\n",
    "        return self.recorded_wav\n",
    "    \n",
    "    @route(\"/denoiser\")\n",
    "    def denoise_record(self):\n",
    "        model = pretrained.dns64()\n",
    "        wav, sr = torchaudio.load(self.recorded_wav)\n",
    "        wav = convert_audio(wav, sr, model.sample_rate, model.chin)\n",
    "        with torch.no_grad():\n",
    "            denoised = model(wav[None])[0]\n",
    "        x=disp.Audio(denoised.data.cpu().numpy(), rate=model.sample_rate)\n",
    "        with open(self.denoised_wav, 'wb') as f:\n",
    "            f.write(x.data)\n",
    "    \n",
    "    \n",
    "    @route(\"/json\")\n",
    "    def generate_words(self):\n",
    "        !deepspeech --json --model {self.deep_speech_pb} --scorer {self.deep_speech_scorer} --audio {self.denoised_wav} >{self.json_path}\n",
    "    def get_words_without_taskeel(self):\n",
    "        right_words=[]\n",
    "        arabic_alphapet=\"ٱأإابتثجحخدذرزسشصضطظعغفقكلمنهويةىآؤءئ\"\n",
    "        with open(self.json_path) as f:\n",
    "            data = json.load(f)\n",
    "        transcripts=data['transcripts']\n",
    "        word_without_taskel=\"\"\n",
    "        for word in transcripts[0]['words']:\n",
    "                word_without_taskel=\"\"\n",
    "                for letter in word[\"word\"]:\n",
    "                    for alpha in arabic_alphapet:\n",
    "                        if(letter==alpha):\n",
    "                            word_without_taskel=word_without_taskel+letter\n",
    "                right_words.append({\"word\":word_without_taskel,\"start_time\":word[\"start_time\"],\n",
    "                                   \"duration\":word[\"duration\"]})\n",
    "        for word in right_words:\n",
    "            print(word[\"word\"],\" \",word[\"start_time\"],\" \",word[\"duration\"])\n",
    "        return right_words\n",
    "    def get_hkm_words(self):\n",
    "        hkm_words=[]\n",
    "        with open(self.meta_data) as f:\n",
    "            data = json.load(f)\n",
    "        transcripts=data['words']\n",
    "        hkm_indexes=data[\"indexes\"]\n",
    "        for idx in hkm_indexes:\n",
    "            hkm_words.append(transcripts[idx][\"word\"])\n",
    "        return hkm_words\n",
    "    \n",
    "        \n",
    "    def get_hkm_time(self):\n",
    "        right_words=self.get_words_without_taskeel()\n",
    "        hkm_words=self.get_hkm_words()\n",
    "        print(\"hkm klmat\")\n",
    "        for word in hkm_words:\n",
    "            print(word)\n",
    "        idx=0\n",
    "        start_time=0.0\n",
    "        duration=0.0\n",
    "        for word in right_words:\n",
    "            if(hkm_words[idx]==word[\"word\"] and idx==0):\n",
    "                start_time=word[\"start_time\"]\n",
    "                duration=word[\"duration\"]\n",
    "                idx=idx+1\n",
    "            elif(hkm_words[idx]==word[\"word\"] and idx!=0):\n",
    "                duration=duration+word[\"duration\"]\n",
    "                idx=idx+1\n",
    "            else:\n",
    "                idx=0\n",
    "            if(len(hkm_words)==idx):\n",
    "                    break;\n",
    "        ans=[-1.0,-1.0]\n",
    "        if(idx==len(hkm_words)):\n",
    "            print(\"start_time:\",start_time)\n",
    "            print(\"duration:\",duration)\n",
    "            ans[0]=start_time\n",
    "            ans[1]=duration\n",
    "        return ans\n",
    "    @route(\"/hkm_record\")\n",
    "    def generate_hkm_record(self,ans):\n",
    "        start_time=ans[0]\n",
    "        duration=ans[1]\n",
    "        !ffmpeg -ss \"$start_time\" -t  \"$duration\" -i \"$self.denoised_wav\" \"$self.generated_wav\" -y\n",
    "    @route(\"/deep_speech\")\n",
    "    def run_deep_speech(self):\n",
    "        self.denoise_record()\n",
    "        self.generate_words()\n",
    "        ans=self.get_hkm_time()\n",
    "        if(ans[0]==-1):\n",
    "            return \"0\"\n",
    "        self.generate_hkm_record(ans)\n",
    "        return \"1\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4c67f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleModel(FlaskView):\n",
    "    def init(self):\n",
    "        self.model_path=\"\"\n",
    "        self.record_path=\"\"\n",
    "    def set_paths(self,paths):\n",
    "        self.model_path=paths[\"rule_path\"]\n",
    "        self.record_path=paths[\"hkm_record\"]\n",
    "        self.x=paths[\"model_x\"]\n",
    "    \n",
    "    def fixing_signal_range (self,file_path , signal ) :\n",
    "        print(self.x)\n",
    "        print(type(self.x))\n",
    "        rate =  self.get_duration(file_path) /self.x;\n",
    "        new_sound_1 = librosa.effects.time_stretch(signal, rate=rate)\n",
    "        return new_sound_1\n",
    "    \n",
    "    \n",
    "    @route(\"/rule\")\n",
    "    def run_model(self):\n",
    "        SAMPLE_RATE = 22050\n",
    "        num_mfcc=13 \n",
    "        n_fft=2048\n",
    "        hop_length=512\n",
    "        file_path = self.record_path\n",
    "        signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "        signal = self.fixing_signal_range (file_path , signal )\n",
    "        mfcc = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "        mfcc = mfcc.T\n",
    "        return self.runModel(mfcc)\n",
    "    def get_duration(self,file_path):\n",
    "        with wave.open(file_path) as mywav:\n",
    "            duration = mywav.getnframes() / mywav.getframerate()\n",
    "        return duration\n",
    "\n",
    "    def runModel (self,mfccs) :\n",
    "        model = models.load_model(self.model_path)\n",
    "        print(self.model_path)\n",
    "        mfccs = np.array(mfccs)\n",
    "        X_train2 = []\n",
    "        temp = np.array(mfccs).flatten()\n",
    "        X_train2.append(temp)\n",
    "        mfccs = X_train2 \n",
    "        mfccs = tf.stack(mfccs)\n",
    "        y_pred = model.predict(mfccs)\n",
    "        if (np.round(y_pred[0]) == 0 ):\n",
    "            return \"1\"\n",
    "        else:\n",
    "            return \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce16d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Record(FlaskView):\n",
    "    def __init__(self):\n",
    "        self.deep_speech=DeepSpeech()\n",
    "        self.rule_model=RuleModel()\n",
    "    @route('/<chunck>', methods=['POST'])\n",
    "    @cross_origin()\n",
    "    def check(self,chunck):\n",
    "        x=\"0\"\n",
    "        if(len(request.data)<800):\n",
    "            self.deep_speech.set_paths()\n",
    "            data = json.loads(request.data)\n",
    "            self.rule_model.set_paths(data)\n",
    "        else:\n",
    "            temp_filename = self.deep_speech.get_root_path()+\"/records/tmp.wav\"\n",
    "            with open(temp_filename, '+wb') as f:\n",
    "                f.write(request.get_data())\n",
    "            audio = AudioSegment.from_file(temp_filename, format=\"webm\")\n",
    "            output_filename = self.deep_speech.get_record_path()\n",
    "            audio.export(output_filename, format=\"wav\")\n",
    "            x=self.deep_speech.run_deep_speech()\n",
    "            print(x)\n",
    "            if(x==\"1\"):\n",
    "                x=self.rule_model.run_model()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0054e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/read_file', methods = ['POST','GET'])\n",
    "@cross_origin()\n",
    "def api_message():\n",
    "    with open(request.data) as f:\n",
    "        data = json.load(f)\n",
    "    transcripts=data['words']\n",
    "    result=\"\"\n",
    "    for word in transcripts:\n",
    "        result=result+word[\"word\"]+\" \"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55fa42d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:2000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [16/May/2023 21:08:40] \"POST /read_file HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:09:18] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:09:18] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:09:18] \"POST /records/save HTTP/1.1\" 200 -\n",
      "TensorFlow: v2.3.0-6-g23ad988fcd\n",
      "DeepSpeech: v0.9.3-0-gf2e9c858\n",
      "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
      "Loading model from file D:/web/deep_speech_models/output.pb\n",
      "Loaded model in 0.206s.\n",
      "Loading scorer from files D:/web/deep_speech_models/quran.scorer\n",
      "Loaded scorer in 0.0185s.\n",
      "Running inference.\n",
      "Inference took 2.323s for 6.120s audio file.\n",
      "127.0.0.1 - - [16/May/2023 21:09:26] \"POST /records/save HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قال   1.2   0.4\n",
      "إن   1.62   0.68\n",
      "ٱلله   2.34   0.5\n",
      "لا   2.92   0.36\n",
      "تثريب   3.3   0.86\n",
      "وجعلنى   4.2   0.8\n",
      "نبيا   5.02   1.08\n",
      "hkm klmat\n",
      "عبد\n",
      "ٱلله\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/May/2023 21:09:55] \"POST /read_file HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:10:02] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:10:02] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:10:02] \"POST /records/save HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قل   1.24   0.14\n",
      "هو   1.4   0.28\n",
      "ٱلله   1.8   0.46\n",
      "أحد   2.34   1.0\n",
      "hkm klmat\n",
      "هو\n",
      "ٱلله\n",
      "start_time: 1.4\n",
      "duration: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow: v2.3.0-6-g23ad988fcd\n",
      "DeepSpeech: v0.9.3-0-gf2e9c858\n",
      "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
      "Loading model from file D:/web/deep_speech_models/output.pb\n",
      "Loaded model in 0.105s.\n",
      "Loading scorer from files D:/web/deep_speech_models/quran.scorer\n",
      "Loaded scorer in 0.00196s.\n",
      "Running inference.\n",
      "Inference took 2.076s for 3.360s audio file.\n",
      "ffmpeg version 6.0-full_build-www.gyan.dev Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 12.2.0 (Rev10, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-d3d11va --enable-dxva2 --enable-libvpl --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : mono\n",
      "Input #0, wav, from 'D:/web/records/denoised_record.wav':\n",
      "  Duration: 00:00:03.36, bitrate: 256 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, 1 channels, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'D:/web/records/result.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf60.3.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.3.100 pcm_s16le\n",
      "size=       0kB time=00:00:00.00 bitrate=N/A speed=N/A    \n",
      "size=      23kB time=00:00:00.64 bitrate= 297.0kbits/s speed=82.3x    \n",
      "video:0kB audio:23kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.329392%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "<class 'int'>\n",
      "D:/web/hkm1/model.h5\n",
      "1/1 [==============================] - 0s 255ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/May/2023 21:10:14] \"POST /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:10:37] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:10:37] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:10:38] \"POST /records/save HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قل   0.8   0.24\n",
      "هو   1.06   0.28\n",
      "ٱلله   1.36   0.6\n",
      "أحد   1.98   1.54\n",
      "hkm klmat\n",
      "هو\n",
      "ٱلله\n",
      "start_time: 1.06\n",
      "duration: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow: v2.3.0-6-g23ad988fcd\n",
      "DeepSpeech: v0.9.3-0-gf2e9c858\n",
      "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
      "Loading model from file D:/web/deep_speech_models/output.pb\n",
      "Loaded model in 0.117s.\n",
      "Loading scorer from files D:/web/deep_speech_models/quran.scorer\n",
      "Loaded scorer in 0.00188s.\n",
      "Running inference.\n",
      "Inference took 1.734s for 3.540s audio file.\n",
      "ffmpeg version 6.0-full_build-www.gyan.dev Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 12.2.0 (Rev10, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-d3d11va --enable-dxva2 --enable-libvpl --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : mono\n",
      "Input #0, wav, from 'D:/web/records/denoised_record.wav':\n",
      "  Duration: 00:00:03.54, bitrate: 256 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, 1 channels, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'D:/web/records/result.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf60.3.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.3.100 pcm_s16le\n",
      "size=       0kB time=00:00:00.00 bitrate=N/A speed=N/A    \n",
      "size=      28kB time=00:00:00.76 bitrate= 294.1kbits/s speed= 154x    \n",
      "video:0kB audio:28kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.276989%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "<class 'int'>\n",
      "D:/web/hkm1/model.h5\n",
      "1/1 [==============================] - 0s 149ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/May/2023 21:10:42] \"POST /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:13:18] \"POST /read_file HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:13:29] \"POST /read_file HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:13:54] \"POST /read_file HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:14:00] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:14:01] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:14:01] \"POST /records/save HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "قل   1.22   0.2\n",
      "هو   1.44   0.34\n",
      "ٱلله   1.84   0.72\n",
      "أحد   2.72   0.98\n",
      "hkm klmat\n",
      "هو\n",
      "ٱلله\n",
      "start_time: 1.44\n",
      "duration: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow: v2.3.0-6-g23ad988fcd\n",
      "DeepSpeech: v0.9.3-0-gf2e9c858\n",
      "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
      "Loading model from file D:/web/deep_speech_models/output.pb\n",
      "Loaded model in 0.109s.\n",
      "Loading scorer from files D:/web/deep_speech_models/quran.scorer\n",
      "Loaded scorer in 0.00175s.\n",
      "Running inference.\n",
      "Inference took 2.211s for 3.720s audio file.\n",
      "ffmpeg version 6.0-full_build-www.gyan.dev Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 12.2.0 (Rev10, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-d3d11va --enable-dxva2 --enable-libvpl --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : mono\n",
      "Input #0, wav, from 'D:/web/records/denoised_record.wav':\n",
      "  Duration: 00:00:03.72, bitrate: 256 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, 1 channels, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'D:/web/records/result.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf60.3.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.3.100 pcm_s16le\n",
      "size=       0kB time=00:00:00.00 bitrate=N/A speed=N/A    \n",
      "size=      33kB time=00:00:01.02 bitrate= 265.6kbits/s speed= 166x    \n",
      "video:0kB audio:33kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.229953%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "<class 'int'>\n",
      "D:/web/hkm1/model.h5\n",
      "1/1 [==============================] - 0s 65ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/May/2023 21:14:06] \"POST /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:15:38] \"POST /read_file HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:15:46] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:15:47] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:15:47] \"POST /records/save HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "وما   0.8   0.48\n",
      "صاحبكم   1.34   1.8\n",
      "بمجنون   3.16   1.5\n",
      "hkm klmat\n",
      "صاحبكم\n",
      "بمجنون\n",
      "start_time: 1.34\n",
      "duration: 3.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow: v2.3.0-6-g23ad988fcd\n",
      "DeepSpeech: v0.9.3-0-gf2e9c858\n",
      "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
      "Loading model from file D:/web/deep_speech_models/output.pb\n",
      "Loaded model in 0.141s.\n",
      "Loading scorer from files D:/web/deep_speech_models/quran.scorer\n",
      "Loaded scorer in 0.00264s.\n",
      "Running inference.\n",
      "Inference took 1.708s for 4.680s audio file.\n",
      "ffmpeg version 6.0-full_build-www.gyan.dev Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 12.2.0 (Rev10, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-d3d11va --enable-dxva2 --enable-libvpl --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : mono\n",
      "Input #0, wav, from 'D:/web/records/denoised_record.wav':\n",
      "  Duration: 00:00:04.68, bitrate: 256 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, 1 channels, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'D:/web/records/result.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf60.3.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.3.100 pcm_s16le\n",
      "size=       0kB time=00:00:00.00 bitrate=N/A speed=N/A    \n",
      "size=     103kB time=00:00:03.20 bitrate= 264.2kbits/s speed=800x    \n",
      "video:0kB audio:103kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.073864%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "<class 'int'>\n",
      "D:/web/hkm3/model.h5\n",
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/May/2023 21:15:54] \"POST /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:16:07] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:16:07] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:16:07] \"POST /records/save HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "وما   0.68   0.46\n",
      "صاحبكم   1.28   1.3\n",
      "بمجنون   2.6   2.18\n",
      "hkm klmat\n",
      "صاحبكم\n",
      "بمجنون\n",
      "start_time: 1.28\n",
      "duration: 3.4800000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow: v2.3.0-6-g23ad988fcd\n",
      "DeepSpeech: v0.9.3-0-gf2e9c858\n",
      "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
      "Loading model from file D:/web/deep_speech_models/output.pb\n",
      "Loaded model in 0.104s.\n",
      "Loading scorer from files D:/web/deep_speech_models/quran.scorer\n",
      "Loaded scorer in 0.00182s.\n",
      "Running inference.\n",
      "Inference took 2.180s for 4.800s audio file.\n",
      "ffmpeg version 6.0-full_build-www.gyan.dev Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 12.2.0 (Rev10, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-d3d11va --enable-dxva2 --enable-libvpl --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : mono\n",
      "Input #0, wav, from 'D:/web/records/denoised_record.wav':\n",
      "  Duration: 00:00:04.80, bitrate: 256 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, 1 channels, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'D:/web/records/result.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf60.3.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.3.100 pcm_s16le\n",
      "size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \n",
      "size=     109kB time=00:00:03.45 bitrate= 258.0kbits/s speed= 710x    \n",
      "video:0kB audio:109kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.070043%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "<class 'int'>\n",
      "D:/web/hkm3/model.h5\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F021978A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/May/2023 21:16:12] \"POST /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:18:07] \"POST /read_file HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:18:21] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:18:21] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:18:21] \"POST /records/save HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "وٱلله   0.88   0.66\n",
      "أنبتكم   1.56   0.98\n",
      "من   2.56   0.16\n",
      "ٱلأرض   2.76   0.72\n",
      "نباتا   3.5   1.46\n",
      "hkm klmat\n",
      "أنبتكم\n",
      "من\n",
      "start_time: 1.56\n",
      "duration: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow: v2.3.0-6-g23ad988fcd\n",
      "DeepSpeech: v0.9.3-0-gf2e9c858\n",
      "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
      "Loading model from file D:/web/deep_speech_models/output.pb\n",
      "Loaded model in 0.104s.\n",
      "Loading scorer from files D:/web/deep_speech_models/quran.scorer\n",
      "Loaded scorer in 0.00175s.\n",
      "Running inference.\n",
      "Inference took 2.209s for 4.980s audio file.\n",
      "ffmpeg version 6.0-full_build-www.gyan.dev Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 12.2.0 (Rev10, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-d3d11va --enable-dxva2 --enable-libvpl --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : mono\n",
      "Input #0, wav, from 'D:/web/records/denoised_record.wav':\n",
      "  Duration: 00:00:04.98, bitrate: 256 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, 1 channels, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'D:/web/records/result.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf60.3.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.3.100 pcm_s16le\n",
      "size=       0kB time=00:00:00.00 bitrate=N/A speed=N/A    \n",
      "size=      36kB time=00:00:01.02 bitrate= 285.6kbits/s speed= 191x    \n",
      "video:0kB audio:36kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.213816%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "<class 'int'>\n",
      "D:/web/hkm4/model.h5\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F021C01EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 70ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/May/2023 21:18:27] \"POST /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:20:20] \"POST /read_file HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:20:29] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:20:30] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:20:30] \"POST /records/save HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "أم   0.74   0.2\n",
      "ٱعبدوا   0.96   0.48\n",
      "ٱلله   1.48   0.64\n",
      "وأطيعوا   2.16   1.76\n",
      "وأطيعون   3.94   1.62\n",
      "hkm klmat\n",
      "ٱعبدوا\n",
      "ٱلله\n",
      "start_time: 0.96\n",
      "duration: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow: v2.3.0-6-g23ad988fcd\n",
      "DeepSpeech: v0.9.3-0-gf2e9c858\n",
      "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
      "Loading model from file D:/web/deep_speech_models/output.pb\n",
      "Loaded model in 0.104s.\n",
      "Loading scorer from files D:/web/deep_speech_models/quran.scorer\n",
      "Loaded scorer in 0.00185s.\n",
      "Running inference.\n",
      "Inference took 2.748s for 5.580s audio file.\n",
      "ffmpeg version 6.0-full_build-www.gyan.dev Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 12.2.0 (Rev10, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-d3d11va --enable-dxva2 --enable-libvpl --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : mono\n",
      "Input #0, wav, from 'D:/web/records/denoised_record.wav':\n",
      "  Duration: 00:00:05.58, bitrate: 256 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, 1 channels, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'D:/web/records/result.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf60.3.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.3.100 pcm_s16le\n",
      "size=       0kB time=00:00:00.00 bitrate=N/A speed=N/A    \n",
      "size=      35kB time=00:00:01.02 bitrate= 280.6kbits/s speed= 365x    \n",
      "video:0kB audio:35kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.217634%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "<class 'int'>\n",
      "D:/web/hkm1/model.h5\n",
      "1/1 [==============================] - 0s 75ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/May/2023 21:20:36] \"POST /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:21:13] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:21:13] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:21:13] \"POST /records/save HTTP/1.1\" 200 -\n",
      "TensorFlow: v2.3.0-6-g23ad988fcd\n",
      "DeepSpeech: v0.9.3-0-gf2e9c858\n",
      "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
      "Loading model from file D:/web/deep_speech_models/output.pb\n",
      "Loaded model in 0.123s.\n",
      "Loading scorer from files D:/web/deep_speech_models/quran.scorer\n",
      "Loaded scorer in 0.00188s.\n",
      "Running inference.\n",
      "Inference took 2.592s for 4.860s audio file.\n",
      "127.0.0.1 - - [16/May/2023 21:21:18] \"POST /records/save HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "أعبد   0.8   0.82\n",
      "ٱلله   1.64   0.44\n",
      "وٱتقوه   2.12   0.94\n",
      "وأطيعوا   3.08   1.76\n",
      "hkm klmat\n",
      "ٱعبدوا\n",
      "ٱلله\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/May/2023 21:21:31] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:21:31] \"OPTIONS /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:21:31] \"POST /records/save HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "أم   0.84   0.2\n",
      "ٱعبدوا   1.06   0.48\n",
      "ٱلله   1.58   0.66\n",
      "وٱتقوه   2.26   1.0\n",
      "وأطيعون   3.28   1.62\n",
      "hkm klmat\n",
      "ٱعبدوا\n",
      "ٱلله\n",
      "start_time: 1.06\n",
      "duration: 1.1400000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow: v2.3.0-6-g23ad988fcd\n",
      "DeepSpeech: v0.9.3-0-gf2e9c858\n",
      "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
      "Loading model from file D:/web/deep_speech_models/output.pb\n",
      "Loaded model in 0.103s.\n",
      "Loading scorer from files D:/web/deep_speech_models/quran.scorer\n",
      "Loaded scorer in 0.00195s.\n",
      "Running inference.\n",
      "Inference took 2.200s for 4.920s audio file.\n",
      "ffmpeg version 6.0-full_build-www.gyan.dev Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 12.2.0 (Rev10, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libaribb24 --enable-libdav1d --enable-libdavs2 --enable-libuavs3d --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libaom --enable-libjxl --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-liblensfun --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-d3d11va --enable-dxva2 --enable-libvpl --enable-libshaderc --enable-vulkan --enable-libplacebo --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint\n",
      "  libavutil      58.  2.100 / 58.  2.100\n",
      "  libavcodec     60.  3.100 / 60.  3.100\n",
      "  libavformat    60.  3.100 / 60.  3.100\n",
      "  libavdevice    60.  1.100 / 60.  1.100\n",
      "  libavfilter     9.  3.100 /  9.  3.100\n",
      "  libswscale      7.  1.100 /  7.  1.100\n",
      "  libswresample   4. 10.100 /  4. 10.100\n",
      "  libpostproc    57.  1.100 / 57.  1.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : mono\n",
      "Input #0, wav, from 'D:/web/records/denoised_record.wav':\n",
      "  Duration: 00:00:04.92, bitrate: 256 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, 1 channels, s16, 256 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'D:/web/records/result.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf60.3.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.3.100 pcm_s16le\n",
      "size=       0kB time=00:00:00.00 bitrate=N/A speed=N/A    \n",
      "size=      36kB time=00:00:01.02 bitrate= 285.6kbits/s speed= 395x    \n",
      "video:0kB audio:36kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.213816%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "<class 'int'>\n",
      "D:/web/hkm1/model.h5\n",
      "1/1 [==============================] - 0s 61ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/May/2023 21:21:37] \"POST /records/save HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/May/2023 21:39:12] \"POST /read_file HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "deepspeech=DeepSpeech()\n",
    "record=Record()\n",
    "rule_model=RuleModel()\n",
    "deepspeech.register(app,route_base = '/')\n",
    "record.register(app,route_base = '/records')\n",
    "rule_model.register(app,route_base = '/rules')\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug= False , host= 'localhost',port=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660e23c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aefbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c7f6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e1efdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d79faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32fec40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b098b248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd77b324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
